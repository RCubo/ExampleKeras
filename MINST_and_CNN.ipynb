{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST image recognition with Keras (Work In Progress...)\n",
    "This notebook explains how to run a simple ConvNN using the Keras using the MINST dataset\n",
    "(Parts of the code come from other's people Kernel in Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#Preprocessing of the images\n",
    "#Input file can be obtained in http://yann.lecun.com/exdb/mnist/\n",
    "input_data = pd.read_csv('MINST/train.csv')\n",
    "raw_images = input_data.iloc[:,1:].values\n",
    "raw_images = raw_images.astype(np.float)\n",
    "\n",
    "#Convert from [0:255] => [0.0:1.0]\n",
    "norm_images = np.multiply(raw_images, 1.0 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Images are stored as 1-D vector\n",
    "print norm_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Resize input images to ROWS X COLUMNS format to be used as input for a Convolution2D\n",
    "ROWS = 28\n",
    "COLUMNS = 28\n",
    "resized_images = []\n",
    "for k in range(0,norm_images.shape[0]):\n",
    "    resized_images.append(norm_images[k].reshape(ROWS,COLUMNS,1))\n",
    "resized_images = np.array(resized_images)\n",
    "print resized_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test of a random resized image\n",
    "#plt.axis('off')\n",
    "#plt.imshow(resized_images[1], cmap=cm.binary)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing of the labels\n",
    "raw_labels = input_data.iloc[:,0].values\n",
    "raw_labels = raw_labels.astype(np.float)\n",
    "\n",
    "print raw_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example of one of the labels and the maximum and minimum\n",
    "print raw_labels[1]\n",
    "print np.amax(raw_labels)\n",
    "print np.amin(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert labels into vector of categories. Class 0 = digit 0... class 9 = digi9\n",
    "nb_classes = 10\n",
    "cat_labels = np_utils.to_categorical(raw_labels, nb_classes)\n",
    "print cat_labels[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shuffling dataset and splling between training and validation with fraction train_frac\n",
    "from sklearn.utils import shuffle\n",
    "shuffled_resized_images, shuffled_cat_labels = shuffle(resized_images, cat_labels, random_state=0)\n",
    "train_frac = 0.99\n",
    "\n",
    "Xtrain = shuffled_resized_images[1:int(shuffled_resized_images.shape[0]*train_frac)]\n",
    "Ytrain = shuffled_cat_labels[1:int(shuffled_resized_images.shape[0]*train_frac)]\n",
    "\n",
    "Xval = shuffled_resized_images[Xtrain.shape[0]:]\n",
    "Yval = shuffled_cat_labels[Ytrain.shape[0]:]\n",
    "\n",
    "\n",
    "print Xtrain.shape\n",
    "print Ytrain.shape\n",
    "print Xval.shape\n",
    "print Yval.shape\n",
    "print Xtrain.shape[0]+Xval.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNN architecture\n",
    "They can be adapted to test different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model Parameters\n",
    "batch_size = 32 # in each iteration, we consider batch_size training examples at once\n",
    "num_epochs = 60 # we iterate n_epoch times over the entire training set\n",
    "kernel_size = 3 # we will use kernel_size x kernel_size filters throughout\n",
    "pool_size = 2 # we will use 2x2 (max)pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "conv_depth_3 = 128 # ...switching to 64 after the second pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 32 # the FC layer will have hidden_size neurons\n",
    "data_augmentation = False # Whether to use or not data augmentation\n",
    "\n",
    "#Architecture\n",
    "inp = Input(shape=(ROWS, COLUMNS,1)) \n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "#conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "conv_2 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "conv_3 = Convolution2D(conv_depth_3, kernel_size, kernel_size, border_mode='same', activation='relu')(pool_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "#conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "#pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "#flat = Flatten()(drop_2)\n",
    "flat = Flatten()(pool_2)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#hidden = Dense(hidden_size, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01), activation='relu')(flat)\n",
    "drop_1 = Dropout(drop_prob_1)(hidden)\n",
    "#out = Dense(num_classes, activation='softmax')(drop_3)\n",
    "out = Dense(nb_classes, activation='softmax')(hidden)\n",
    "model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "#print the summary of the architecture\n",
    "model.summary()\n",
    "\n",
    "#Visulize the model if desired\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='Example_of_CNN_MINST.pdf')\n",
    "\n",
    "# reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=0.0000001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's train the model using SGD without data augmentation\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "#For future testing...\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) \n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmpsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Let's train the SGD model WITHOUT using data augmentation\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(Xtrain, Ytrain, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          validation_data=(Xval, Yval), shuffle=True, callbacks=[reduce_lr])\n",
    "\n",
    "# Let's train the SGD model using data augmentation\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    #See http://machinelearningmastery.com/image-augmentation-deep-learning-keras/ for the infividual\n",
    "    #effects of each parameter in ImageDataGenerator\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=True, # apply ZCA whitening\n",
    "        #zoom_range=0.1\n",
    "        #Not really needed for MINST because images are centerd\n",
    "        #rotation_range=20,   \n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "    )\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(Xtrain)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(Xtrain, Ytrain,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=Xtrain.shape[0], #For each epoch generate Xtrain.shape[0] new images for training\n",
    "                        nb_epoch=num_epochs,\n",
    "                        validation_data=(Xval, Yval),\n",
    "                        #validation_data=(Xtrain, Ytrain),\n",
    "                        callbacks=[reduce_lr]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Accuracy_MINST.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Loss_MINST.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Example_ConvNN_MINST.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Example_ConvNN_MINST.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and re-test the performance in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(\"Example_ConvNN_MINST.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Example_ConvNN_MINST.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on  data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "score_train = loaded_model.evaluate(Xtrain, Ytrain, verbose=0)\n",
    "score_val = loaded_model.evaluate(Xtrain, Ytrain, verbose=0)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score_train[1]*100)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score_val[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions in new and unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing of the images\n",
    "test_data = pd.read_csv('MINST/test.csv')\n",
    "test_images = test_data.iloc[:,:].values\n",
    "test_images = test_images.astype(np.float)\n",
    "\n",
    "#Convert from [0:255] => [0.0:1.0]\n",
    "norm_test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "print norm_test_images.shape\n",
    "\n",
    "#Resize input images to ROWS X COLUMNS format to be used as input for a Convolution2D\n",
    "resized_test_images = []\n",
    "for k in range(0,norm_test_images.shape[0]):\n",
    "    resized_test_images.append(norm_test_images[k].reshape(ROWS,COLUMNS,1))\n",
    "resized_test_images = np.array(resized_test_images)\n",
    "print resized_test_images.shape\n",
    "\n",
    "#Make predictions\n",
    "test_pred_prob = model.predict(resized_test_images)\n",
    "print test_pred_prob.shape\n",
    "print test_pred_prob[0]\n",
    "\n",
    "#Select the classes with highest probabilities as class predictions\n",
    "test_pred = np.argmax(test_pred_prob, axis=1)\n",
    "print test_pred[0]\n",
    "\n",
    "#Save the predictions\n",
    "from datetime import datetime\n",
    "np.savetxt('mnist-predictions-ConvNN%s.csv' % datetime.now().strftime('%Y-%m-%d_%H%M'), np.c_[range(1, len(test_pred) + 1), test_pred], delimiter = ',', header = 'ImageId,Label', comments = '', fmt='%d')\n",
    "print(\"Predictions Ready\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
