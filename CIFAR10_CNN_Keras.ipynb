{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: image recognition with Keras using CIFAR10 (Work In Progress...)\n",
    "This notebook explains how to run a simple ConvNN using the Keras with the Cifar10 dataset (Parts of the code come from other's people Kernel in Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading keras deep learnig libraries to build the model: https://keras.io/ \n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of the input dataset\n",
    "In the CIFAR dataset the images are 32x32x3 (RGB) and they are classified in 10 different categories, namely:\n",
    "\n",
    "airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "\n",
    "In the next block we will read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = X_train.shape[3]\n",
    "\n",
    "# The CIFAR10 images are 10 different classes.\n",
    "nb_classes = y_train[1][0]+1\n",
    "\n",
    "print y_test[5000]\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print Y_test[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNN arquitechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model Parameters\n",
    "batch_size = 32 # in each iteration, we consider batch_size training examples at once\n",
    "num_epochs = 100 # we iterate num_epochs times over the entire training set\n",
    "kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "conv_depth_3 = 128 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 256 # the FC layer will have 512 neurons\n",
    "data_augmentation = True # Whether to use or not data augmentation\n",
    "\n",
    "#Architecture\n",
    "inp = Input(shape=(img_rows, img_cols, img_channels)) # N.B. depth goes first in Keras!\n",
    "# Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "#conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "conv_1 = Convolution2D(conv_depth_1, kernel_size, kernel_size, border_mode='same', activation='relu')(inp)\n",
    "pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_1)\n",
    "conv_2 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(pool_1)\n",
    "pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "conv_3 = Convolution2D(conv_depth_3, kernel_size, kernel_size, border_mode='same', activation='relu')(pool_2)\n",
    "#pool_3 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_3)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "# Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "#conv_3 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, kernel_size, kernel_size, border_mode='same', activation='relu')(conv_3)\n",
    "#pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "# Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "#flat = Flatten()(drop_2)\n",
    "flat = Flatten()(conv_3)\n",
    "hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "#out = Dense(nb_classes, activation='softmax')(drop_3)\n",
    "out = Dense(nb_classes, activation='softmax')(hidden)\n",
    "model = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "#print the summary of the architecture\n",
    "model.summary()\n",
    "\n",
    "#Visulize the model if desired\n",
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='Example_of_CNN_cifar.pdf')\n",
    "\n",
    "# reduce the learning rate by factor of 0.5 if the validation loss does not get lower in 7 epochs\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=0.0000001, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's train the model using SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Let's train the SGD model WITHOUT using data augmentation\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=num_epochs,\n",
    "          validation_data=(X_test, Y_test), shuffle=True, callbacks=[reduce_lr])\n",
    "\n",
    "# Let's train the SGD model using data augmentation\n",
    "else:\n",
    "    print('Using real-time data augmentation.')    \n",
    "  \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        #Not really needed for MINST because images are centerd, but might work for CIFAR10\n",
    "        #zoom_range=0.1, \n",
    "        rotation_range=20,   \n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip = True\n",
    "    )\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0], #For each epoch generate Xtrain.shape[0] new images for training\n",
    "                        nb_epoch=num_epochs,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        #validation_data=(X_train, Y_train),\n",
    "                        callbacks=[reduce_lr]\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Accuracy_CIFAR10.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('Loss_CIFAR10.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Example_ConvNN_CIFAR10.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Example_ConvNN_CIFAR10.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and re-test the performance in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open(\"Example_ConvNN_CIFAR10.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"Example_ConvNN_CIFAR10.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "score_train = loaded_model.evaluate(X_train, Y_train, verbose=0)\n",
    "score_test = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print \"Training %s: %.2f%%\" % (loaded_model.metrics_names[1], score_train[1]*100)\n",
    "print \"Test %s: %.2f%%\" % (loaded_model.metrics_names[1], score_test[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
